
## requirements
- python 3.10
- requirements.txt
- conda: pandas, deprecated, #pyjsparser
<!-- - npm: esprima -->

## usage
- python src/main.py


## 思考
- 7.18：目前的实现是每个文件统计一个特征，并直接计算分数。后面可能设计为“多个规则”，每个规则涉及到多个特征，满足特定规则后再判断更深的规则。（规则是偏序的，且不一定要遍历所有规则）
- 7.19：对JS用JS的规则，

## 问题
1. 对HTML和JS的处理方法不同，需要单独判断，无法直接递归读取文件夹来处理？
2. 爬取的内容与ctrl+G看到的内容差异很大。比如缺少了很多link和内联JS。
3. 尝试使用scrapy？
### Malicious URL Detection using Machine Learning: A Survey
#### HTML-survey19
1. 平均单词长度
    恶意内容指示：较长的单词可能指示复杂或加密的恶意代码。
    可读性评估：帮助判断文本的可读性，恶意网页通常会使用复杂的术语。

2. 总单词数
    内容丰富性：总单词数可以反映网页内容的丰富程度，恶意网页往往内容较少。
    爬虫检测：低单词数可能表明该网页是生成的或不真实。

3. 不同单词数
    多样性分析：较高的不同单词数表示文本多样性，通常与正常内容相关。
    重复内容检测：低不同单词数可能暗示内容重复，增加恶意性质的可能性。

4. 每行单词数
    格式化判断：每行单词数可以反映页面的格式和布局，异常的排版可能是恶意设计的迹象。
    可读性影响：过多或过少的单词数可能影响读者的体验，恶意页面通常会故意设计以混淆用户。
- 此外还提到了NULL字符数量、字符串拼接函数、不对称HTML标签、外部脚本链接、超链接（a）、不可见对象数量、iframe（总数和零大小）、行数、小区域元素数、可疑内容元素数、不符合常规位置或结构的元素数量、双文档检测、版本变化检测
#### JS-survey19
1. 常用 JavaScript 函数的使用计数：
    eval()
    unescape()
    escape()
    link()
    exec()
    search()

2. 关键字与单词的比例：
3. 长字符串数量：
4. 解码例程的存在：
5. shell 代码存在的概率：
6. 直接字符串赋值的数量：
7. DOM 修改函数的数量：
8. 事件绑定的数量：
9. 可疑对象名称的数量：
10. 可疑字符串的数量：
11. "iframe" 字符串的数量：
12. 可疑字符串标签的数量：
